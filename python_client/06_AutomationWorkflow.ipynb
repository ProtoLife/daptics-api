{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation Workflow Tutorial <a class=\"tocSkip\">\n",
    "\n",
    "This notebook contains an interactive introduction to the Python DapticsClient class,\n",
    "a simplified interface for accessing the Daptics GraphQL API for the optimization of\n",
    "experimental design.\n",
    "\n",
    "Documentation for using the DapticsClient class (implemented in the daptics_client.py\n",
    "file in this folder) is included as comment lines in the interactive Python cells of\n",
    "this notebook.\n",
    "\n",
    "For additional help or information, please visit or contact Daptics.\n",
    "\n",
    "On the web at https://daptics.ai\n",
    "By email at support@daptics.ai\n",
    "\n",
    "Daptics API Version 0.12.0\n",
    "Copyright (c) 2021 Daptics Inc.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), the rights to use, copy, modify, merge, publish, and/or distribute, copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "You do not have the right to sub-license or sell copies of the Software.\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation<a class=\"tocSkip\">\n",
    "\n",
    "Before running this project, please make sure that your Jupyter Python environment supports Python 3, and has these required packages installed:\n",
    "*   chardet\n",
    "*   urllib3\n",
    "*   requests\n",
    "*   gql\n",
    "*   pandas    \n",
    "\n",
    "You will also need a validated user account on the Daptics API server.  You can create an account by [registering](https:daptics.ai/register) at https://daptics.ai, or contacting our sales department at sales@daptics.ai\n",
    "\n",
    "See the **01_README.ipynb** notebook in this folder for more information on installing necessary modules\n",
    "to work with the Daptics API.\n",
    "\n",
    "Review the **02_Terminology.ipynb** notebook to gain an understanding of how Daptics works, and\n",
    "way you set up the engine using experimental space parameters.\n",
    "\n",
    "The next cell gives an example of the information necessary to connect, log in, create a session,\n",
    "and define the \"experimental space\" for your campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the API client environment.\n",
    "# Requirements are Python 3, and the `gql` and `requests` libraries.\n",
    "\n",
    "# Import required classes from the daptics_client package.\n",
    "from daptics_client import DapticsClient, DapticsTaskType, DapticsExperimentsType\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os.path\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#for some demo plots:\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/overview.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fresh start\n",
    "! rm -rf output\n",
    "! mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize values for all variables that will be used to\n",
    "# connect to the Daptics API and perform automated design of\n",
    "# experiments via CSV files.\n",
    "\n",
    "# The URL for the API server.\n",
    "api_host_url = 'https://api.daptics.ai'\n",
    "\n",
    "# The credentials for an active Daptics account.\n",
    "# Please contact sales@daptics.ai for information on\n",
    "# how to obtain an account.\n",
    "email = 'YOUR_EMAIL@YOUR_DOMAIN'\n",
    "password = 'YOUR_PASSWORD'\n",
    "\n",
    "# You will store the session unique identifier and the generation\n",
    "# number for the last design in a file that your automation workflow\n",
    "# software can read. The values in this file will let the automation\n",
    "# software pick up the appropriate design file.\n",
    "session_file = './output/session.json'\n",
    "\n",
    "# The location of the CSV file that defines the names and possible\n",
    "# values for each input parameter for an individual experiment.\n",
    "csv_space_file = './input/experimental_space.csv'\n",
    "\n",
    "# The location of the CSV file that your automation workflow software\n",
    "# will create after performing all the experiments in a Daptics-\n",
    "# generated design and adding the Response value for each\n",
    "# experiment.\n",
    "csv_experiments_file = './input/experiments.csv'\n",
    "\n",
    "# The location where Daptics will create CSV files for designed\n",
    "# experiments.\n",
    "output_path = './output'\n",
    "\n",
    "# Configuration options used for automated processing.\n",
    "auto_options = {\n",
    "    # Create CSV files at each step in this directory.\n",
    "    'auto_export_path': output_path,\n",
    "    # Let long-running tasks execute for up to one hour.\n",
    "    'auto_task_timeout': 3600,\n",
    "    # Automatically generate the next design when results are uploaded.\n",
    "    'auto_generate_next_design': True\n",
    "}\n",
    "\n",
    "# The experimental meta-parameters that define the type of experiment\n",
    "# campaign you will be doing, and the number of experiments that will\n",
    "# be explored at each gneration. The combination of these meta-\n",
    "# parameters and the definition of the input parameters is called the\n",
    "# \"experimental space\" for the campaign.\n",
    "space_params = {\n",
    "    # The 'factorial' experimental space type is used for\n",
    "    # unconstrained input parameters.\n",
    "    'space': { 'type': 'factorial' },\n",
    "    # Each design generated will contain 30 independent experiments.\n",
    "    'populationSize': 30,\n",
    "    # And will have 2 copies of these experiments, so the total\n",
    "    # number of experiments to be performed at each generation will\n",
    "    # be 30 * 3 = 90.\n",
    "    'replicates': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the First Design <a class=\"tocSkip\">\n",
    "\n",
    "With modules and variables set up, you must place a CSV file that\n",
    "defines the names and possible values for each input parameter\n",
    "that will be used in your experiemnts. This should be saved to a\n",
    "CSV file at the location specified in the `csv_space_file` variable.\n",
    "\n",
    "Once this file is there, you can connect to the API server, log in,\n",
    "create a session for your experimental campaign, and have Daptics\n",
    "generate a first batch of experiments for the automation workflow\n",
    "software to perform and assay.\n",
    "\n",
    "When you run the next cell, you should see task retry progress\n",
    "messages, for the validation of the space and for the creation\n",
    "of the first generation design. The process should take about\n",
    "a minute if you use the example `experimental_space.csv` file\n",
    "in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the session Automated Workflow 20220730-154206.\n",
      "Creating the experimental space. This may take a minute or more.\n",
      "Task status = running after 1 retries...\n",
      "Task completed!\n",
      "Creating an initial design. This may take a minute or more.\n",
      "Task status = running after 2 retries...\n",
      "Task completed!\n",
      "All done. Generation 1 design is now available in output directory.\n"
     ]
    }
   ],
   "source": [
    "# With all the Python requirements satisfied, and using the variables\n",
    "# previously defined, you can go ahead and generate your first\n",
    "# experimental design generation.\n",
    "\n",
    "# Initialize values for additional variables that will be used to\n",
    "# create a Daptics session for your workflow and generate an\n",
    "# initial design.\n",
    "\n",
    "# Identify the session. Typically, your workflow software will\n",
    "# have a unique identifier that can be used as the session\n",
    "# name. If not, here's a way to make a unique name for your session.\n",
    "session_name = datetime.now().strftime('Automated Workflow %Y%m%d-%H%M%S')\n",
    "\n",
    "# A description for the session\n",
    "session_description = 'Fully automated example'\n",
    "\n",
    "# Now you can connect to the API, create a session, set up the\n",
    "# experimental space for your campaign, and generate the first\n",
    "# design of experiments.\n",
    "\n",
    "# Create a Python client instance, connecting to the beta API server.\n",
    "daptics = DapticsClient(api_host_url)\n",
    "\n",
    "# Set up the options that will fully automate client processing.\n",
    "daptics.options = auto_options\n",
    "\n",
    "# The 'connect' method will connect to the API server and obtain the\n",
    "# GraphQL schema.\n",
    "daptics.connect()\n",
    "\n",
    "# Log into the API using your Daptics account credentials.\n",
    "daptics.login(email, password)\n",
    "\n",
    "print('Creating the session {}.'.format(session_name))\n",
    "\n",
    "# Create a new 'session' for this experimental campaign.\n",
    "daptics.create_session(session_name, session_description)\n",
    "\n",
    "print('Creating the experimental space. This may take a minute or more.')\n",
    "\n",
    "# Upload the CSV file containing the names and possible values for\n",
    "# each experimental input parameter, and set other meta-parameters,\n",
    "# to completely initialize the Daptics engine for this campaign.\n",
    "daptics.put_experimental_parameters_csv(csv_space_file, space_params)\n",
    "\n",
    "# Because the `auto_task_timeout` option was set, the Python script\n",
    "# will block here, until the space has been validated and set up.\n",
    "\n",
    "# Now the Daptics engine is set up. At this point, if you have any\n",
    "# initial experiments that have been performed by your workflow,\n",
    "# instead of calling `daptics.generate_design()`, you can upload\n",
    "# these experiments from a CSV that your automation workflow software\n",
    "# has created, containing the input parameter and the response values\n",
    "# for each of these \"initial experiments\".\n",
    "\n",
    "# Here is how you would be use the API to upload initial experiments:\n",
    "# daptics.put_experiments_csv(\n",
    "#    DapticsExperimentsType.INITIAL_EXTRAS_ONLY,\n",
    "#    csv_experiments_file)\n",
    "\n",
    "print('Creating an initial design. This may take a minute or more.')\n",
    "\n",
    "# If you have no initial experiments to upload, you will just\n",
    "# ask Daptics to generate the first design.\n",
    "daptics.generate_design()\n",
    "\n",
    "# Because the `auto_task_timeout` and `auto_generate_next_design`\n",
    "# options were set in the client, if either the `put_experiments_csv`\n",
    "# or `generate_design` methods were called, the Python script will\n",
    "# block here until the design for the first generation has completed.\n",
    "\n",
    "# Because the `auto_export_path` option was set, when the design\n",
    "# has been generated, it will have been saved into a CSV file at\n",
    "# `./output/auto_gen1_design.csv`, ready for your workflow software\n",
    "# to read.\n",
    "\n",
    "# Before this script exits, you must save the session id, generation\n",
    "# number and design file location, so that the automation software\n",
    "# can later read the design and reconnect to the session to upload\n",
    "# the results obtained by peforming the designed experiments.\n",
    "\n",
    "# The name of the automatically generated design file is constructed\n",
    "# using the pattern shown here.\n",
    "gen = daptics.gen\n",
    "csv_design_file = os.path.join(\n",
    "    output_path, 'auto_gen{}_design.csv'.format(gen))\n",
    "session_data = {\n",
    "    'session_id': daptics.session_id,\n",
    "    'gen': gen,\n",
    "    'csv_design_file': csv_design_file\n",
    "}\n",
    "with open(session_file, 'wt') as f:\n",
    "    json.dump(session_data, f)\n",
    "\n",
    "print('All done. Generation {} design is now available in output directory.'.format(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param1,numerical,0,1,2,3,4,5,6,7\n",
      "param2,numerical,0,1,2,3,4,5,6,7\n",
      "param3,numerical,0,1,2,3,4,5,6,7\n",
      "param4,numerical,0,1,2,3,4,5,6,7\n"
     ]
    }
   ],
   "source": [
    "!cat input/experimental_space.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_gen1_design.csv     auto_validated_space.csv session.json\n"
     ]
    }
   ],
   "source": [
    "!ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note:  the settings for `auto_options` are designed for real-time notebook execution:  notebook cells will block until server execution is finished, reporting the number of retries as the server is polled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the Loop: Perform Experiments <a class=\"tocSkip\">\n",
    "\n",
    "After the initial design is generated, the automation workflow software\n",
    "will read the input parameters from the file `auto_gen1_design.csv`\n",
    "in the directory specified by the Python variable `output_path`.\n",
    "Each row in the CSV file represents a unique experiment, with the\n",
    "values specified for each input parameter in the column with the\n",
    "parameter's name.\n",
    "\n",
    "The workflow software must convert these input parameter names and\n",
    "values into an experimental workflow, mapping inputs to plate wells,\n",
    "pipetting appropriate reagents, performing incubation and\n",
    "filtration, etc., and finally conducting assays.\n",
    "The workflow software must also convert the assay results\n",
    "from each experiment into a single target number, called the\n",
    "experiment \"Response\". This is the number that the Daptics AI will optimize.\n",
    "\n",
    "The workflow software must add these responses to the Daptics-generated\n",
    "design file. The response to each experiment should be written into the `Response`\n",
    "column of the CSV file in the row that corresponds to the experiment.\n",
    "The CSV file is saved to the location specified in the `csv_experiments_file`\n",
    "Python variable: `./input/experiments.csv`.\n",
    "\n",
    "If you don't have real experimental results, you can run the next\n",
    "cell to create a valid experiments file, filled with random responses,\n",
    "at the `csv_experiments_file` location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated random experiment responses saved.\n"
     ]
    }
   ],
   "source": [
    "# Simulate experiments by filling in random responses.\n",
    "\n",
    "# This code expects that the `daptics` client is still connected\n",
    "# to the API and that the `session_data` variable has been\n",
    "# initialized or updated after the previous design generation.\n",
    "# If these variables are not set up, you will have to reconnect\n",
    "# to the API as in the next code cell below.\n",
    "\n",
    "# This client method returns the validated experimental\n",
    "# space for the session, as a Python `dict`.\n",
    "space = daptics.get_experimental_space()\n",
    "\n",
    "# The client's `design` attribute should contain the last\n",
    "# design generated:\n",
    "design = daptics.design\n",
    "\n",
    "# Or you could construct the design from the data in the\n",
    "# `auto_genN_design.csv` file:\n",
    "import csv\n",
    "\n",
    "with open(session_data['csv_design_file'], newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    col_headers = next(reader, [])\n",
    "    data = [row for row in reader]\n",
    "    design = {\n",
    "        'designRows': len(data),\n",
    "        'validated': True,\n",
    "        'hasResponses': False,\n",
    "        'gen': session_data['gen'],\n",
    "        'table': {\n",
    "            'colHeaders': col_headers,\n",
    "            'data': data\n",
    "        }\n",
    "    }\n",
    "\n",
    "# This client utility method merges random experimental\n",
    "# responses into the design, returning the merged\n",
    "# data as a Python `dict`.\n",
    "experiments = daptics.random_experiments_with_responses(space, design)\n",
    "\n",
    "# Then use this client utility method to save the experiments\n",
    "# with random responses to location that will be used by the next code cell.\n",
    "daptics.export_csv(csv_experiments_file, experiments, True)\n",
    "\n",
    "print('Simulated random experiment responses saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the experiments file has loaded responses for each of the experiments in the design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['7', '6', '3', '0', ''],\n",
       " ['4', '7', '4', '0', ''],\n",
       " ['5', '1', '7', '1', ''],\n",
       " ['6', '1', '6', '3', ''],\n",
       " ['0', '1', '2', '4', ''],\n",
       " ['5', '1', '7', '7', ''],\n",
       " ['0', '6', '7', '1', ''],\n",
       " ['2', '3', '0', '5', ''],\n",
       " ['4', '7', '0', '3', ''],\n",
       " ['0', '0', '1', '7', '']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daptics.design['table']['data'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param1,param2,param3,param4,Response\n",
      "7,6,3,0,3.118\n",
      "4,7,4,0,4.056\n",
      "5,1,7,1,0.891\n",
      "6,1,6,3,0.559\n",
      "0,1,2,4,4.435\n",
      "5,1,7,7,1.951\n",
      "0,6,7,1,3.251\n",
      "2,3,0,5,1.444\n",
      "4,7,0,3,0.298\n"
     ]
    }
   ],
   "source": [
    "!head {csv_experiments_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_gen1_design.csv     auto_validated_space.csv session.json\n"
     ]
    }
   ],
   "source": [
    "!ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the Loop: Design Next Generation<a class=\"tocSkip\">\n",
    "\n",
    "Once an experiments file has bee put into the `csv_experiments_file`\n",
    "locatoin, you can execute the next part of the Daptics process,\n",
    "simply uploading the experiments and their responses and generating the\n",
    "next design. To do so you must reconnect to the session using the\n",
    "`session_id` value saved previously. Once reconnected, the only\n",
    "API call necessary is to upload the experiments.\n",
    "\n",
    "When you run the next cell, you should see task retry progress\n",
    "messages, for the incorporation of the experiments into the\n",
    "model, and for the creation of the next generation design.\n",
    "These processes should take about a minute, but could take longer\n",
    "for more complicated experimental spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconnecting to session S97nfh5bmzf3m2jkzrf5.\n",
      "Uploading experiments and creating a design.\n",
      "This may take a minute or more.\n",
      "Task status = running after 1 retries...\n",
      "Task failed with error(s)!  Messages are:\n",
      "[0] category:\texecution\n",
      "[0] fatalError:\tNone\n",
      "[0] message:\tExperiments in Experiments2.csv do not match those of generation 2\n",
      "[0] systemError:\tNone\n",
      "Generation 2 design is now available in output directory.\n"
     ]
    }
   ],
   "source": [
    "# Design the next generation by reading in the experiments\n",
    "# saved in the `csv_experiments_file`.\n",
    "\n",
    "# If you put this code into a separate script for your automation\n",
    "# workflow engine, make sure to include code from the first Python\n",
    "# cell in this tutorial that contains the imports and variables used\n",
    "# here.\n",
    "\n",
    "# To begin you reload the session data you saved when you generated\n",
    "# the previous design.\n",
    "with open(session_file, 'rt') as f:\n",
    "    session_data = json.load(f)\n",
    "\n",
    "# You follow the same connect and login procedure as for the first\n",
    "# design, then reconnect to your session.\n",
    "\n",
    "# Create a Python client instance, connecting to the beta API server.\n",
    "daptics = DapticsClient(api_host_url)\n",
    "\n",
    "# Set up the options that will fully automate client processing.\n",
    "daptics.options = auto_options\n",
    "\n",
    "# The 'connect' method will connect to the API server and obtain the\n",
    "# GraphQL schema.\n",
    "daptics.connect()\n",
    "\n",
    "# Log into the API using your Daptics account credentials.\n",
    "daptics.login(email, password)\n",
    "\n",
    "print('Reconnecting to session {}.'.format(session_data['session_id']))\n",
    "\n",
    "# Reconnect to the session after logging in. Here you rely\n",
    "# on the 'session_id' value saved in the session file.\n",
    "daptics.reconnect_session(session_data['session_id'])\n",
    "\n",
    "print('Uploading experiments and creating a design.')\n",
    "print('This may take a minute or more.')\n",
    "\n",
    "# Upload the experiments file that your automation workflow software\n",
    "# created, containing the previous design and the response values\n",
    "# for each experiment in the design.\n",
    "daptics.put_experiments_csv(\n",
    "    DapticsExperimentsType.DESIGNED_WITH_OPTIONAL_EXTRAS,\n",
    "    csv_experiments_file)\n",
    "\n",
    "# Because the `auto_task_timeout` and `auto_generate_next_design`\n",
    "# options were set in the client, the Python script will\n",
    "# block here until the design for the next generation has completed.\n",
    "\n",
    "# Because the `auto_export_path` option was set, when the design\n",
    "# has been generated, it will have been saved into a CSV file at\n",
    "# `./output/auto_genN_design.csv`, where `N` is the generation\n",
    "# number, ready for your workflow software to read.\n",
    "\n",
    "# Before this script exits, you again save the session id, generation\n",
    "# number and design file location, to make this updated information\n",
    "# available to the workflow software.\n",
    "\n",
    "# The name of the automatically generated design file is constructed\n",
    "# using the pattern shown here.\n",
    "gen = daptics.gen\n",
    "csv_design_file = os.path.join(\n",
    "    output_path, 'auto_gen{}_design.csv'.format(gen))\n",
    "session_data = {\n",
    "    'session_id': daptics.session_id,\n",
    "    'gen': gen,\n",
    "    'csv_design_file': csv_design_file\n",
    "}\n",
    "with open(session_file, 'wt') as f:\n",
    "    json.dump(session_data, f)\n",
    "\n",
    "print('Generation {} design is now available in output directory.'.format(gen))\n",
    "\n",
    "# Now the workflow software can read the design file, execute more\n",
    "# experiments, and continue the loop. You can exit the script now.\n",
    "\n",
    "# Or you can optionally generate analytics graphs at each step of\n",
    "# the loop. These PDF files can then be picked up by automation\n",
    "# software and included in your lab notebook, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconnecting to session S97nfh5bmzf3m2jkzrf5.\n",
      "Generating analytics files.\n",
      "Task status = running after 5 retries...\n",
      "Task completed!\n",
      "Downloading analytics files.\n",
      "Generation 2 analytics are now available in output directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To begin you reload the session data you saved when you generated\n",
    "# the previous design.\n",
    "with open(session_file, 'rt') as f:\n",
    "    session_data = json.load(f)\n",
    "\n",
    "# You follow the same connect and login procedure as for the first\n",
    "# design, then reconnect to your session.\n",
    "\n",
    "# Create a Python client instance, connecting to the beta API server.\n",
    "daptics = DapticsClient(api_host_url)\n",
    "\n",
    "# Set up the options that will fully automate client processing.\n",
    "daptics.options = auto_options\n",
    "\n",
    "# The 'connect' method will connect to the API server and obtain the\n",
    "# GraphQL schema.\n",
    "daptics.connect()\n",
    "\n",
    "# Log into the API using your Daptics account credentials.\n",
    "daptics.login(email, password)\n",
    "\n",
    "print('Reconnecting to session {}.'.format(session_data['session_id']))\n",
    "\n",
    "# Reconnect to the session after logging in. Here you rely\n",
    "# on the 'session_id' value saved in the session file.\n",
    "daptics.reconnect_session(session_data['session_id'])\n",
    "\n",
    "print('Generating analytics files.')\n",
    "\n",
    "# Generate any analytics files that are available for this generation.\n",
    "# Since the `auto_task_timeout` option has been set, the script will\n",
    "# block until the files are ready to be downloaded.\n",
    "daptics.generate_analytics()\n",
    "\n",
    "print('Downloading analytics files.')\n",
    "\n",
    "# Fetch the PDF analytics files via authenticated HTTP, and save them\n",
    "# to the './output' directory, where your automation workflow\n",
    "# software can pick them up.\n",
    "daptics.download_all_analytics_files(daptics.analytics, output_path, name_by_gen=True)\n",
    "\n",
    "print('Generation {} analytics are now available in output directory.'.format(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param1,param2,param3,param4,Response\n",
      "7,6,6,0,1.025\n",
      "0,3,1,1,2.360\n",
      "2,7,6,2,1.475\n",
      "2,2,2,1,4.359\n",
      "4,6,4,3,4.199\n",
      "4,7,3,1,0.510\n",
      "3,7,1,0,3.912\n",
      "7,7,5,1,0.684\n",
      "0,1,7,4,1.764\n"
     ]
    }
   ],
   "source": [
    "!head input/experiments.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the Loop: Next Generation<a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate the experiments<a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated random experiment responses saved.\n"
     ]
    }
   ],
   "source": [
    "# This client method returns the validated experimental\n",
    "# space for the session, as a Python `dict`.\n",
    "space = daptics.get_experimental_space()\n",
    "\n",
    "# The client's `design` attribute should contain the last\n",
    "# design generated:\n",
    "design = daptics.design\n",
    "\n",
    "# Or you could construct the design from the data in the\n",
    "# `auto_genN_design.csv` file:\n",
    "import csv\n",
    "\n",
    "with open(session_data['csv_design_file'], newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    col_headers = next(reader, [])\n",
    "    data = [row for row in reader]\n",
    "    design = {\n",
    "        'designRows': len(data),\n",
    "        'validated': True,\n",
    "        'hasResponses': False,\n",
    "        'gen': session_data['gen'],\n",
    "        'table': {\n",
    "            'colHeaders': col_headers,\n",
    "            'data': data\n",
    "        }\n",
    "    }\n",
    "\n",
    "# This client utility method merges random experimental\n",
    "# responses into the design, returning the merged\n",
    "# data as a Python `dict`.\n",
    "experiments = daptics.random_experiments_with_responses(space, design)\n",
    "\n",
    "# Then use this client utility method to save the experiments\n",
    "# with random responses to location that will be used by the next code cell.\n",
    "daptics.export_csv(csv_experiments_file, experiments, True)\n",
    "\n",
    "print('Simulated random experiment responses saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the experiments file has loaded responses for each of the experiments in the design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['5', '7', '7', '0', ''],\n",
       " ['6', '7', '7', '1', ''],\n",
       " ['3', '7', '0', '7', ''],\n",
       " ['2', '7', '3', '6', ''],\n",
       " ['0', '5', '7', '5', ''],\n",
       " ['6', '7', '7', '5', ''],\n",
       " ['5', '6', '7', '7', ''],\n",
       " ['5', '4', '4', '7', ''],\n",
       " ['6', '7', '6', '0', ''],\n",
       " ['3', '2', '3', '1', '']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daptics.design['table']['data'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param1,param2,param3,param4,Response\n",
      "5,7,7,0,1.057\n",
      "6,7,7,1,3.184\n",
      "3,7,0,7,4.008\n",
      "2,7,3,6,2.479\n",
      "0,5,7,5,2.120\n",
      "6,7,7,5,4.377\n",
      "5,6,7,7,2.453\n",
      "5,4,4,7,2.098\n",
      "6,7,6,0,0.436\n"
     ]
    }
   ],
   "source": [
    "!head input/experiments.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execute design <a class=\"tocSkip\">\n",
    "\n",
    "Reconnect with server (as if you had disconnected while doing the experiments)\n",
    "    \n",
    "[this cell may be skipped if you are already connected with the server]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconnecting to session S97nfh5bmzf3m2jkzrf5.\n",
      "Uploading experiments and creating a design.\n",
      "This may take a minute or more.\n"
     ]
    }
   ],
   "source": [
    "# Design the next generation by reading in the experiments\n",
    "# saved in the `csv_experiments_file`.\n",
    "\n",
    "# If you put this code into a separate script for your automation\n",
    "# workflow engine, make sure to include code from the first Python\n",
    "# cell in this tutorial that contains the imports and variables used\n",
    "# here.\n",
    "\n",
    "# To begin you reload the session data you saved when you generated\n",
    "# the previous design.\n",
    "with open(session_file, 'rt') as f:\n",
    "    session_data = json.load(f)\n",
    "\n",
    "# You follow the same connect and login procedure as for the first\n",
    "# design, then reconnect to your session.\n",
    "\n",
    "# Create a Python client instance, connecting to the beta API server.\n",
    "daptics = DapticsClient(api_host_url)\n",
    "\n",
    "# Set up the options that will fully automate client processing.\n",
    "daptics.options = auto_options\n",
    "\n",
    "# The 'connect' method will connect to the API server and obtain the\n",
    "# GraphQL schema.\n",
    "daptics.connect()\n",
    "\n",
    "# Log into the API using your Daptics account credentials.\n",
    "daptics.login(email, password)\n",
    "\n",
    "print('Reconnecting to session {}.'.format(session_data['session_id']))\n",
    "\n",
    "# Reconnect to the session after logging in. Here you rely\n",
    "# on the 'session_id' value saved in the session file.\n",
    "daptics.reconnect_session(session_data['session_id'])\n",
    "\n",
    "print('Uploading experiments and creating a design.')\n",
    "print('This may take a minute or more.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload experiments from the last generation.  Create the new design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task status = running after 5 retries...\n",
      "Task completed!\n",
      "\n",
      "Task completed!\n",
      "Generation 3 design is now available in output directory.\n"
     ]
    }
   ],
   "source": [
    "# Upload the experiments file that your automation workflow software\n",
    "# created, containing the previous design and the response values\n",
    "# for each experiment in the design.\n",
    "daptics.put_experiments_csv(\n",
    "    DapticsExperimentsType.DESIGNED_WITH_OPTIONAL_EXTRAS,\n",
    "    csv_experiments_file)\n",
    "\n",
    "# Because the `auto_task_timeout` and `auto_generate_next_design`\n",
    "# options were set in the client, the Python script will\n",
    "# block here until the design for the next generation has completed.\n",
    "\n",
    "# Because the `auto_export_path` option was set, when the design\n",
    "# has been generated, it will have been saved into a CSV file at\n",
    "# `./output/auto_genN_design.csv`, where `N` is the generation\n",
    "# number, ready for your workflow software to read.\n",
    "\n",
    "# Before this script exits, you again save the session id, generation\n",
    "# number and design file location, to make this updated information\n",
    "# available to the workflow software.\n",
    "\n",
    "# The name of the automatically generated design file is constructed\n",
    "# using the pattern shown here.\n",
    "gen = daptics.gen\n",
    "csv_design_file = os.path.join(\n",
    "    output_path, 'auto_gen{}_design.csv'.format(gen))\n",
    "session_data = {\n",
    "    'session_id': daptics.session_id,\n",
    "    'gen': gen,\n",
    "    'csv_design_file': csv_design_file\n",
    "}\n",
    "with open(session_file, 'wt') as f:\n",
    "    json.dump(session_data, f)\n",
    "\n",
    "print('Generation {} design is now available in output directory.'.format(gen))\n",
    "\n",
    "# Now the workflow software can read the design file, execute more\n",
    "# experiments, and continue the loop. You can exit the script now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [optionally] generate analytics <a class=\"tocSkip\">\n",
    "    \n",
    "[this cell may be skipped if you are doing many generations and want to look at analytics only at the end.]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task status = running after 4 retries...\n",
      "Task completed!\n",
      "\n",
      "Task completed!\n",
      "Generation 3 design is now available in output directory.\n",
      "Generating analytics files.\n",
      "Task status = running after 3 retries..."
     ]
    }
   ],
   "source": [
    "# Or you can optionally generate analytics graphs at each step of\n",
    "# the loop. These PDF files can then be picked up by automation\n",
    "# software and included in your lab notebook, etc.\n",
    "\n",
    "print('Generating analytics files.')\n",
    "\n",
    "# Generate any analytics files that are available for this generation.\n",
    "# Since the `auto_task_timeout` option has been set, the script will\n",
    "# block until the files are ready to be downloaded.\n",
    "daptics.generate_analytics()\n",
    "\n",
    "print('Downloading analytics files.')\n",
    "\n",
    "# Fetch the PDF analytics files via authenticated HTTP, and save them\n",
    "# to the './output' directory, where your automation workflow\n",
    "# software can pick them up.\n",
    "daptics.download_all_analytics_files(daptics.analytics, output_path, name_by_gen=True)\n",
    "\n",
    "print('Generation {} analytics are now available in output directory.'.format(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the Loop: Next Generation<a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate the experiments<a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated random experiment responses saved.\n"
     ]
    }
   ],
   "source": [
    "# This client method returns the validated experimental\n",
    "# space for the session, as a Python `dict`.\n",
    "space = daptics.get_experimental_space()\n",
    "\n",
    "# The client's `design` attribute should contain the last\n",
    "# design generated:\n",
    "design = daptics.design\n",
    "\n",
    "# Or you could construct the design from the data in the\n",
    "# `auto_genN_design.csv` file:\n",
    "import csv\n",
    "\n",
    "with open(session_data['csv_design_file'], newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    col_headers = next(reader, [])\n",
    "    data = [row for row in reader]\n",
    "    design = {\n",
    "        'designRows': len(data),\n",
    "        'validated': True,\n",
    "        'hasResponses': False,\n",
    "        'gen': session_data['gen'],\n",
    "        'table': {\n",
    "            'colHeaders': col_headers,\n",
    "            'data': data\n",
    "        }\n",
    "    }\n",
    "\n",
    "# This client utility method merges random experimental\n",
    "# responses into the design, returning the merged\n",
    "# data as a Python `dict`.\n",
    "experiments = daptics.random_experiments_with_responses(space, design)\n",
    "\n",
    "# Then use this client utility method to save the experiments\n",
    "# with random responses to location that will be used by the next code cell.\n",
    "daptics.export_csv(csv_experiments_file, experiments, True)\n",
    "\n",
    "print('Simulated random experiment responses saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the experiments file has loaded responses for each of the experiments in the design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6', '6', '1', '0', ''],\n",
       " ['1', '7', '5', '5', ''],\n",
       " ['7', '0', '0', '7', ''],\n",
       " ['6', '4', '6', '4', ''],\n",
       " ['4', '2', '4', '3', ''],\n",
       " ['1', '6', '5', '4', ''],\n",
       " ['4', '2', '4', '3', ''],\n",
       " ['6', '6', '1', '0', ''],\n",
       " ['4', '4', '1', '5', ''],\n",
       " ['3', '3', '6', '7', '']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daptics.design['table']['data'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param1,param2,param3,param4,Response\n",
      "6,6,1,0,1.902\n",
      "1,7,5,5,2.907\n",
      "7,0,0,7,2.586\n",
      "6,4,6,4,0.477\n",
      "4,2,4,3,2.840\n",
      "1,6,5,4,0.896\n",
      "4,2,4,3,0.867\n",
      "6,6,1,0,3.369\n",
      "4,4,1,5,1.720\n"
     ]
    }
   ],
   "source": [
    "!head input/experiments.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execute design <a class=\"tocSkip\">\n",
    "\n",
    "Reconnect with server (as if you had disconnected while doing the experiments)\n",
    "    \n",
    "[this cell may be skipped if you are already connected with the server]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconnecting to session S97nfh5bmzf3m2jkzrf5.\n",
      "Uploading experiments and creating a design.\n",
      "This may take a minute or more.\n"
     ]
    }
   ],
   "source": [
    "# Design the next generation by reading in the experiments\n",
    "# saved in the `csv_experiments_file`.\n",
    "\n",
    "# If you put this code into a separate script for your automation\n",
    "# workflow engine, make sure to include code from the first Python\n",
    "# cell in this tutorial that contains the imports and variables used\n",
    "# here.\n",
    "\n",
    "# To begin you reload the session data you saved when you generated\n",
    "# the previous design.\n",
    "with open(session_file, 'rt') as f:\n",
    "    session_data = json.load(f)\n",
    "\n",
    "# You follow the same connect and login procedure as for the first\n",
    "# design, then reconnect to your session.\n",
    "\n",
    "# Create a Python client instance, connecting to the beta API server.\n",
    "daptics = DapticsClient(api_host_url)\n",
    "\n",
    "# Set up the options that will fully automate client processing.\n",
    "daptics.options = auto_options\n",
    "\n",
    "# The 'connect' method will connect to the API server and obtain the\n",
    "# GraphQL schema.\n",
    "daptics.connect()\n",
    "\n",
    "# Log into the API using your Daptics account credentials.\n",
    "daptics.login(email, password)\n",
    "\n",
    "print('Reconnecting to session {}...'.format(session_data['session_id']))\n",
    "\n",
    "# Reconnect to the session after logging in. Here you rely\n",
    "# on the 'session_id' value saved in the session file.\n",
    "daptics.reconnect_session(session_data['session_id'])\n",
    "\n",
    "print('Reconnected.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload experiments from the last generation.  Create the new design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading experiments and creating a design.\n",
      "This may take a minute or more.\n",
      "Task status = running after 4 retries...\n",
      "Task completed!\n",
      "\n",
      "Task completed!\n",
      "Generation 4 design is now available in output directory.\n"
     ]
    }
   ],
   "source": [
    "print('Uploading experiments and creating a design.')\n",
    "print('This may take a minute or more.')\n",
    "\n",
    "# Upload the experiments file that your automation workflow software\n",
    "# created, containing the previous design and the response values\n",
    "# for each experiment in the design.\n",
    "daptics.put_experiments_csv(\n",
    "    DapticsExperimentsType.DESIGNED_WITH_OPTIONAL_EXTRAS,\n",
    "    csv_experiments_file)\n",
    "\n",
    "# Because the `auto_task_timeout` and `auto_generate_next_design`\n",
    "# options were set in the client, the Python script will\n",
    "# block here until the design for the next generation has completed.\n",
    "\n",
    "# Because the `auto_export_path` option was set, when the design\n",
    "# has been generated, it will have been saved into a CSV file at\n",
    "# `./output/auto_genN_design.csv`, where `N` is the generation\n",
    "# number, ready for your workflow software to read.\n",
    "\n",
    "# Before this script exits, you again save the session id, generation\n",
    "# number and design file location, to make this updated information\n",
    "# available to the workflow software.\n",
    "\n",
    "# The name of the automatically generated design file is constructed\n",
    "# using the pattern shown here.\n",
    "gen = daptics.gen\n",
    "csv_design_file = os.path.join(\n",
    "    output_path, 'auto_gen{}_design.csv'.format(gen))\n",
    "session_data = {\n",
    "    'session_id': daptics.session_id,\n",
    "    'gen': gen,\n",
    "    'csv_design_file': csv_design_file\n",
    "}\n",
    "with open(session_file, 'wt') as f:\n",
    "    json.dump(session_data, f)\n",
    "\n",
    "print('Generation {} design is now available in output directory.'.format(gen))\n",
    "\n",
    "# Now the workflow software can read the design file, execute more\n",
    "# experiments, and continue the loop. You can exit the script now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [optionally] generate analytics <a class=\"tocSkip\">\n",
    "    \n",
    "[this cell may be skipped if you are doing many generations and want to look at analytics only at the end.]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating analytics files.\n",
      "Task status = running after 5 retries..."
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api-files.daptics.ai', port=443): Max retries exceeded with url: /session/S97nfh5bmzf3m2jkzrf5/analytics/gen/3/PredRespProfile2D.pdf?token=QTEyOEdDTQ.fzRqKs95aMkSWaKnTUxdWrC0se_FGz9x62s8S-UpK60sATEBdhanXIoeXVE.iVb7DpOy7QI15LLf.EXN4HFyCgqGtXfa5BA4vzwmRwWxKxpqZ4v008HzJdGfu907KXQAzGRzIBZY1UgwlBlfaTX-8z6nqqznXDj8KeUGKbZaTaOTXLpPnYuBR7RSAfOUOejxEN5Tl7kn9kI13_xBXtzqTZCRqQNKijI-b3f6Y_HUToq-XPo8k7xjNn86x1Vv49DZYrzLKj-Ph9H7W7W5zx34725khBt5KQHBrjxFEM4mgm_xLng.UcB4xy2SIOQ5sR3QM6RxgA (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x10843e910>: Failed to establish a new connection: [Errno 60] Operation timed out'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/connection.py:169\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/util/connection.py:96\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/util/connection.py:86\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 86\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/connectionpool.py:699\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/connectionpool.py:382\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/connectionpool.py:1010\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1010\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/connection.py:353\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/connection.py:181\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x10843e910>: Failed to establish a new connection: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/requests/adapters.py:439\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 439\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/connectionpool.py:755\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    753\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 755\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/urllib3/util/retry.py:574\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    576\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api-files.daptics.ai', port=443): Max retries exceeded with url: /session/S97nfh5bmzf3m2jkzrf5/analytics/gen/3/PredRespProfile2D.pdf?token=QTEyOEdDTQ.fzRqKs95aMkSWaKnTUxdWrC0se_FGz9x62s8S-UpK60sATEBdhanXIoeXVE.iVb7DpOy7QI15LLf.EXN4HFyCgqGtXfa5BA4vzwmRwWxKxpqZ4v008HzJdGfu907KXQAzGRzIBZY1UgwlBlfaTX-8z6nqqznXDj8KeUGKbZaTaOTXLpPnYuBR7RSAfOUOejxEN5Tl7kn9kI13_xBXtzqTZCRqQNKijI-b3f6Y_HUToq-XPo8k7xjNn86x1Vv49DZYrzLKj-Ph9H7W7W5zx34725khBt5KQHBrjxFEM4mgm_xLng.UcB4xy2SIOQ5sR3QM6RxgA (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x10843e910>: Failed to establish a new connection: [Errno 60] Operation timed out'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerating analytics files.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Generate any analytics files that are available for this generation.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Since the `auto_task_timeout` option has been set, the script will\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# block until the files are ready to be downloaded.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mdaptics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_analytics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading analytics files.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Fetch the PDF analytics files via authenticated HTTP, and save them\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# to the './output' directory, where your automation workflow\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# software can pick them up.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/daptics-api/python_client/daptics_client/daptics_client.py:2806\u001b[0m, in \u001b[0;36mDapticsClient.generate_analytics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2804\u001b[0m task_id \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreateAnalytics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaskId\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   2805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_info[task_id] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreateAnalytics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2806\u001b[0m auto_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreateAnalytics\u001b[39m\u001b[38;5;124m'\u001b[39m: auto_task}\n",
      "File \u001b[0;32m~/Projects/daptics-api/python_client/daptics_client/daptics_client.py:2730\u001b[0m, in \u001b[0;36mDapticsClient._auto_task\u001b[0;34m(self, timeout_override)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2730\u001b[0m data, errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_current_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_exception_on_error(data, errors)\n\u001b[1;32m   2734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrentTask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/daptics-api/python_client/daptics_client/daptics_client.py:2680\u001b[0m, in \u001b[0;36mDapticsClient.wait_for_current_task\u001b[0;34m(self, task_type, timeout)\u001b[0m\n\u001b[1;32m   2678\u001b[0m retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 2680\u001b[0m     data, errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll_for_current_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrentTask\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrentTask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2682\u001b[0m         status \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrentTask\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/daptics-api/python_client/daptics_client/daptics_client.py:2638\u001b[0m, in \u001b[0;36mDapticsClient.poll_for_current_task\u001b[0;34m(self, task_type)\u001b[0m\n\u001b[1;32m   2636\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalytics \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalytics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   2637\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m auto_export_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2638\u001b[0m                     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_all_analytics_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2639\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalytics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_export_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2641\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrentTask\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n",
      "File \u001b[0;32m~/Projects/daptics-api/python_client/daptics_client/daptics_client.py:2848\u001b[0m, in \u001b[0;36mDapticsClient.download_all_analytics_files\u001b[0;34m(self, analytics, directory, name_by_gen)\u001b[0m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m   2847\u001b[0m     url, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_url_and_params(file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 2848\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m requests\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mok \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2850\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/requests/api.py:76\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/requests/sessions.py:542\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    537\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    540\u001b[0m }\n\u001b[1;32m    541\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 542\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/requests/sessions.py:655\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 655\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    658\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/requests/adapters.py:516\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api-files.daptics.ai', port=443): Max retries exceeded with url: /session/S97nfh5bmzf3m2jkzrf5/analytics/gen/3/PredRespProfile2D.pdf?token=QTEyOEdDTQ.fzRqKs95aMkSWaKnTUxdWrC0se_FGz9x62s8S-UpK60sATEBdhanXIoeXVE.iVb7DpOy7QI15LLf.EXN4HFyCgqGtXfa5BA4vzwmRwWxKxpqZ4v008HzJdGfu907KXQAzGRzIBZY1UgwlBlfaTX-8z6nqqznXDj8KeUGKbZaTaOTXLpPnYuBR7RSAfOUOejxEN5Tl7kn9kI13_xBXtzqTZCRqQNKijI-b3f6Y_HUToq-XPo8k7xjNn86x1Vv49DZYrzLKj-Ph9H7W7W5zx34725khBt5KQHBrjxFEM4mgm_xLng.UcB4xy2SIOQ5sR3QM6RxgA (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x10843e910>: Failed to establish a new connection: [Errno 60] Operation timed out'))"
     ]
    }
   ],
   "source": [
    "# Or you can optionally generate analytics graphs at each step of\n",
    "# the loop. These PDF files can then be picked up by automation\n",
    "# software and included in your lab notebook, etc.\n",
    "\n",
    "print('Generating analytics files.')\n",
    "\n",
    "# Generate any analytics files that are available for this generation.\n",
    "# Since the `auto_task_timeout` option has been set, the script will\n",
    "# block until the files are ready to be downloaded.\n",
    "daptics.generate_analytics()\n",
    "\n",
    "print('Downloading analytics files.')\n",
    "\n",
    "# Fetch the PDF analytics files via authenticated HTTP, and save them\n",
    "# to the './output' directory, where your automation workflow\n",
    "# software can pick them up.\n",
    "daptics.download_all_analytics_files(daptics.analytics, output_path, name_by_gen=True)\n",
    "\n",
    "print('Generation {} analytics are now available in output directory.'.format(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,python//py:light"
  },
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
